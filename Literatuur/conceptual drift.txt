	100,5,31,2
Since the FCC has a	neurological basis,	it changes very	slowly for a single person.	It falls back about 3rpm per decade
the cadence was steady in a 12-week longitudinal perspective at the same time as it was highly individualistic. Hansen EA, Ohnstad AE. Evidence for freely chosen pedalling rate during submaximal cycling to be a robust innate voluntary motor rhythm.

In het algemeen hebben ML algoritmes geen mechanisme om een veranderend concept (conceptual drift) snel op te volgen. Ze convergeren naar
	het veranderd concept because of diluting the previously learned concept over time. 

Het veranderen van fietsersmodel: fietsermodel van gem koppel => snelheid of helling
	https://tel.archives-ouvertes.fr/tel-01812044v2/document Dit legt dit goed uit (p27...)
	verwachting: een verandering van fietsersmodel zal leiden tot een ander rijgedrag waardoor er grote fouten ontstaant. Om dit nieuw concept 
	te leren (wanneer er al een bestaand, verschillend concept is geleerd) zal er veel meer moeten geleerd worden dan het leren vanaf 0. Dit komt
	omdat modellen by default geen "forget" mechanisme hebben. Training data wordt gedilute totdat het nieuwe concept een groter aandeel heeft in
	de trainingset als het oude concept.
	
	SW (20) verlaagt het aantal trainingen minimaal (45 -> 36). SW (15) doet het net iets beter (45-> 34). SW (10) doet het slechter. Dit is
	waarschijnlijk te klein zodat vorige trainingen niet meer in de dataset zitten. Hierbij moeten we ook nog weten dat we de trainingset aanvullen
	met het eigenlijke fietsersmodel, wat in werkelijkheid niet mogelijk is. in werkelijkheid zou de voorspelde cadans + of - d worden gedaan en
	dit in de set gestoken. Als het verschil te groot is tussen het originele concept en het nieuwe concept, kan het veel langer duren dan in 
	de simulatie.
	Do we need to cope with conceptual drift? Ik denk het niet. Een mens trapt altijd hetzelfde, als de fiets van gebruiker wisselt (bij verkoop bv)
	kunnen we best terug van 0 beginnen? mss reset button of verschillende "saves".
	
	Een mogelijkheid is Fixed size windowing (hou een set van lengte X bij). Dump oudere data voor nieuwe data
		+ Simpel mechanisme voor leren en vergeten, geen complex mechanisme nodig zoals bij adaptive SW
		+ technically start het model met updaten bij het eerste moment dat er conceptual drift is (kan meer responsive zijn dan drift detector)
		- een correcte window size is moeilijk te vinden 
		( if the window is too small, the model might react quickly to abrupt drifts but also over-react to noisy observations.)
		- een te klein window heeft mogelijk te weinig data om het concept te leren
		+ groot window zorgt er waarschijnlijk voor dat het model meer robust is tegen noise && accuraat model voor stabiel concept
		- groot window veranderd trager
		- vulnerable to noisy observations 
		
	Adaptive size windowing (size is set according to a change detector)
		groeit window wanneer er geen verschil gededecteerd wordt, verkleinen wanneer er een verschil is. 
		=> waardoor observaties relevant blijven in het huidige concept
		- moeilijk om een change detector te maken dat omgaat met een grote range van scenarios
			and to take relevant decision once an alarm is triggered (alles of een deel weggooien)
		
			
	Sampling (meer nakijken)
		Another solution would be to sample the observations which will be used to
		learn from. Sampling algorithms try to summarize the characteristics of the whole stream
		by retaining into memory the observations which have been selected according to a given
		probability distribution. In particular, this probability distribution might be biased in favor
		of the most recent observations in order to account for the drifts.
		
		+this strategy will work well, when there is a constrain on the maximum memory available but where it is desirable to
		retain as much of the past knowledge as possible.
		- trainingset zal data bevatten van "a little bit of everything" => vaak conceptual drift werkt niet goed hier
		
		t:new training item
		r: reservoir
		f: % full of reservoir [0,1]
		add t to r # bij algoritme 3.1 voegen we t toe met kans p => kunnen kleiner reservoir gebruiken
		with prob f, delete a random point in r (1=100% kans om een random punt te verwijderen)
	
	Fading factor
		Aan elke observatie een weight geven. Dit zal verkleinen over tijd (fading factor bepaald hoe snel het verkleint)
		best voor gradual drift.
		+ past observations keep having a positive effect
		- past observations kunnen ook een negatief effect hebben (i.e. als het noisy is)
		- hoe kiezen we deze fading factor
		
		
		
	Forgetting
		verschillende situaties (abrupt, gradual, reocurring,...)
		In dit geval abrupt 
		Sliding Windows
			This strategy is best suited for gradual drifts but might lack reactivity in cases of abrupt drifts
			of high magnitude for instance. (waarschijnlijk niet het geval dat de verschillen tussen fietsers groot is)
			Adaptive SW is risky, leaves the algorithm exposed to catastrophic forgetting. Als er foutief geschat wordt dat het concept veranderd
			(met noisy data bv) dan verliest ge eigelijk een groot deel aan valuable data

One of the major advantage of using a detection mechanism is the additional information
provided. Once a change has been correctly detected, it is indeed possible to characterize and
quantify the extent of this change.

The difficulty is that it is very challenging, based on a threshold parameter. Too low and noise will trigger it. Too high and it might not
detect gradual change

Global update (i.e. delete and reconstruct model) is a dangerous strategy. This works good if you have reocurring abrupt drifts. Keep different
models in memory, and choose based on detector. => No need to reconstruct model.

"why sliding window isn't suitible"
	Assumption that time is a criterion to decide wether an observation should be kept or deleted
	It is necessary to keep contiguous observations
		
		
DEA heeft weet van de algoritmes in de ensemble (F = {f^1,...,f^n}) en houdt een map met druppels (droplets) (Map = {D^1,...,D^p} in het geheugen. Elke druppel D^t is geassocieerd 
met een observatie x_t (het centrum van de druppel), een radius en houdt bij welk algoritme f^i de kleinste fout heeft in de regio rond de druppel D^t. 

Bij een nieuwe observatie x_k worden de overlappende druppels OD_k berekend. Als OD_k leeg is, wordt de dichtstbijzijnde druppel gekozen om een voorspelling te maken. Als OD_k niet 
leeg is, wordt een meerderheidsstemming genomen.

Bij het trainen van nieuwe observaties x_k worden er nieuwe druppels D^k toegevoegd aan de map. Alle onderliggende algoritmes trainen om (x_k, y_k), maken dan een voorspelling en 
ondervinden een bepaalde error. Als er hier een uniek algoritme de minimale error heeft, dan wordt deze toegewezen aan de druppel D^k. Zijn er meerdere algoritmes, dan worden de som 
van de errors die deze algoritmes maken bij de N dichtste druppels bekeken. Als hier een unieke winnaar uitkomt, wordt deze toegewezen aan de druppel D^k. Zijn er meerdere, dan wordt
 de zoekruimte vergroot naar N+1, N+2,... De nieuwe druppel D^k krijgt een standaard radius toegewezen. Als druppel D^k overlapt met andere druppels, dan wordt de radius van alle 
 druppels die een foutieve voorspelling hebben gemaakt bij de nieuwe observatie x_k verkleint.

DEA kan omgaan met conceptuele drift omdat het de invloed van druppels verlaagt wanneer er foute voorspellingen zijn gemaakt. Zolang dat het algoritme geassocieerd met een druppel 
juiste voorspellingen maakt, blijft het gebruikt worden ongeacht de leeftijd van de druppel. Als het concept veranderd en de voorspellingen van een algoritme geassocieerd met die 
druppel fout zijn, dan wordt deze druppel uiteindelijk zo klein dat het verwijderd zal worden (aangezien het aantal druppel gelimiteerd is).