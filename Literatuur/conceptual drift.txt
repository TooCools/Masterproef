100,5,31,2

In het algemeen hebben ML algoritmes geen mechanisme om een veranderend concept (conceptual drift) snel op te volgen. Ze convergeren naar
	het veranderd concept because of diluting the previously learned concept over time. 

Het veranderen van fietsersmodel: fietsermodel van gem koppel => snelheid of helling
	https://tel.archives-ouvertes.fr/tel-01812044v2/document Dit legt dit goed uit (p27...)
	verwachting: een verandering van fietsersmodel zal leiden tot een ander rijgedrag waardoor er grote fouten ontstaant. Om dit nieuw concept 
	te leren (wanneer er al een bestaand, verschillend concept is geleerd) zal er veel meer moeten geleerd worden dan het leren vanaf 0. Dit komt
	omdat modellen by default geen "forget" mechanisme hebben. Training data wordt gedilute totdat het nieuwe concept een groter aandeel heeft in
	de trainingset als het oude concept.
	
	SW (20) verlaagt het aantal trainingen minimaal (45 -> 36). SW (15) doet het net iets beter (45-> 34). SW (10) doet het slechter. Dit is
	waarschijnlijk te klein zodat vorige trainingen niet meer in de dataset zitten. Hierbij moeten we ook nog weten dat we de trainingset aanvullen
	met het eigenlijke fietsersmodel, wat in werkelijkheid niet mogelijk is. in werkelijkheid zou de voorspelde cadans + of - d worden gedaan en
	dit in de set gestoken. Als het verschil te groot is tussen het originele concept en het nieuwe concept, kan het veel langer duren dan in 
	de simulatie.
	Do we need to cope with conceptual drift? Ik denk het niet. Een mens trapt altijd hetzelfde, als de fiets van gebruiker wisselt (bij verkoop bv)
	kunnen we best terug van 0 beginnen? mss reset button of verschillende "saves".
	
	Een mogelijkheid is Fixed size windowing (hou een set van lengte X bij). Dump oudere data voor nieuwe data
		+ Simpel mechanisme voor leren en vergeten, geen complex mechanisme nodig zoals bij adaptive SW
		+ technically start het model met updaten bij het eerste moment dat er conceptual drift is (kan meer responsive zijn dan drift detector)
		- een correcte window size is moeilijk te vinden 
		( if the window is too small, the model might react quickly to abrupt drifts but also over-react to noisy observations.)
		- een te klein window heeft mogelijk te weinig data om het concept te leren
		+ groot window zorgt er waarschijnlijk voor dat het model meer robust is tegen noise && accuraat model voor stabiel concept
		- groot window veranderd trager
		- vulnerable to noisy observations 
		
	Adaptive size windowing (size is set according to a change detector)
		groeit window wanneer er geen verschil gededecteerd wordt, verkleinen wanneer er een verschil is. 
		=> waardoor observaties relevant blijven in het huidige concept
		- moeilijk om een change detector te maken dat omgaat met een grote range van scenarios
			and to take relevant decision once an alarm is triggered (alles of een deel weggooien)
		
			
	Sampling (meer nakijken)
		Another solution would be to sample the observations which will be used to
		learn from. Sampling algorithms try to summarize the characteristics of the whole stream
		by retaining into memory the observations which have been selected according to a given
		probability distribution. In particular, this probability distribution might be biased in favor
		of the most recent observations in order to account for the drifts.
		
		+this strategy will work well, when there is a constrain on the maximum memory available but where it is desirable to
		retain as much of the past knowledge as possible.
		- trainingset zal data bevatten van "a little bit of everything" => vaak conceptual drift werkt niet goed hier
	
	Fading factor
		Aan elke observatie een weight geven. Dit zal verkleinen over tijd (fading factor bepaald hoe snel het verkleint)
		best voor gradual drift.
		+ past observations keep having a positive effect
		- past observations kunnen ook een negatief effect hebben (i.e. als het noisy is)
		- hoe kiezen we deze fading factor
		
		
		
	Forgetting
		verschillende situaties (abrupt, gradual, reocurring,...)
		In dit geval abrupt 
		Sliding Windows
			This strategy is best suited for gradual drifts but might lack reactivity in cases of abrupt drifts
			of high magnitude for instance. (waarschijnlijk niet het geval dat de verschillen tussen fietsers groot is)
			Adaptive SW is risky, leaves the algorithm exposed to catastrophic forgetting. Als er foutief geschat wordt dat het concept veranderd
			(met noisy data bv) dan verliest ge eigelijk een groot deel aan valuable data

One of the major advantage of using a detection mechanism is the additional information
provided. Once a change has been correctly detected, it is indeed possible to characterize and
quantify the extent of this change.

The difficulty is that it is very challenging, based on a threshold parameter. Too low and noise will trigger it. Too high and it might not
detect gradual change

Global update (i.e. delete and reconstruct model) is a dangerous strategy. This works good if you have reocurring abrupt drifts. Keep different
models in memory, and choose based on detector. => No need to reconstruct model.

"why sliding window isn't suitible"
	Assumption that time is a criterion to decide wether an observation should be kept or deleted
	It is necessary to keep contiguous observations
		